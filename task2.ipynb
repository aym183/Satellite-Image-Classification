{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Classification/Regression (Use all features)\n",
    "\n",
    "Write a Python program to build a MLP classifier and evaluate your modelâ€™s performance. For this task, you should use the pre-processed and transformed dataset without feature selection from Task 3.1.\n",
    "\n",
    "<span style=\"font-weight:bold;\">Save your response (program and markdown) as task2.ipynb</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when to use linear regression\n",
    "\n",
    "# TRY GPU FOR RUNNING PROGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt \n",
    "from functions.pre_processing import *\n",
    "from functions.transformations import *\n",
    "from functions.feature_selection import *\n",
    "from functions.analysis import *\n",
    "from functions.classifiers import *\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Pre-Processing and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = fetch_datasets()\n",
    "x_train_norm, x_test_norm = normalise_min_max(x_train, x_test)\n",
    "# x_train_norm, x_test_norm = normalise_std_scaler(x_train, x_test)\n",
    "\n",
    "# x_train_norm, x_test_norm = normalise_robust_scaler(x_train, x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## MLP Classifier Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Holdout Validation ------\n",
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.9255555555555556\n"
     ]
    }
   ],
   "source": [
    "mlp_training = mlp_classifier(x_train, x_test, y_train, y_test, \"holdout\")\n",
    "mlp_training = mlp_classifier(x_train, x_test, y_train, y_test, \"cv\")\n",
    "mlp_training = mlp_classifier(x_train, x_test, y_train, y_test, \"k_fold\")\n",
    "mlp_training = mlp_classifier(x_train, x_test, y_train, y_test, \"k_fold_strat\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use nested CV here\n",
    "# Confusion Matrix & Classification Report\n",
    "\n",
    "# Make this a module?\n",
    "\n",
    "# max_iters?\n",
    "hidden_layers = [(50,50,50), (50,100,50), (100,)]\n",
    "activations = ['tanh', 'relu']\n",
    "solvers = ['sgd', 'adam']\n",
    "alphas = [0.0001, 0.05]\n",
    "\n",
    "outer_cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "for layer in range(len(hidden_layers)):\n",
    "     for activation in range(len(activations)):\n",
    "          for solver in range(len(solvers)):\n",
    "               for alpha in alphas:\n",
    "                    inner_scores = []\n",
    "                    mlp = MLPClassifier(hidden_layer_sizes=hidden_layers[layer], activation=activations[activation], solver=solvers[solver], alpha=alphas[alpha])\n",
    "                    mlp.fit(x_train, y_train)\n",
    "                    current_train = mlp.score(x_train, y_train) \n",
    "                    current_test = mlp.score(x_test, y_test) \n",
    "\n",
    "                    for train_index, val_index in outer_cv.split(x_train):\n",
    "                         X_train, X_val = x_train[train_index], x_train[val_index]\n",
    "                         Y_train, Y_val = y_train[train_index], y_train[val_index]\n",
    "                         mlp_classifier.fit(X_train, Y_train)\n",
    "                         training_score = mlp_classifier.score(X_train, Y_train)\n",
    "                         test_score = mlp_classifier.score(X_val, Y_val)\n",
    "                         inner_scores.append(test_score)\n",
    "                    \n",
    "                    mean_score = sum(inner_scores) / len(inner_scores)\n",
    "\n",
    "                    print(f\"------- With hidden_layers={hidden_layers[layer]}, activation={activations[activation]}, solver={solvers[solver]}, alpha={alphas[alpha]}\")\n",
    "                    print(f\"Mean - {mean_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
