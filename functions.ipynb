{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "from sklearn.feature_selection import r_regression, f_regression, VarianceThreshold\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This file contains all the functions required in pre-processing the datasets \n",
    "'''\n",
    "def fetch_datasets() -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    ''' \n",
    "    Fetches all the datasets from the datasets folder\n",
    "\n",
    "    Returns:\n",
    "    tuple\n",
    "        All the loaded datasets\n",
    "    '''\n",
    "    x_train = np.load(\"./datasets/x_train.npy\")\n",
    "    x_test = np.load(\"./datasets/x_test.npy\")\n",
    "    y_train = np.load(\"./datasets/y_train.npy\")\n",
    "    y_test = np.load(\"./datasets/y_test.npy\")\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def find_missing_values(input_array: np.ndarray) -> dict:\n",
    "    ''' \n",
    "    Finds the missing values (if any) in all the datasets\n",
    "\n",
    "    Parameters:\n",
    "    input_array: np.ndarray\n",
    "        The dataset values\n",
    "    array_name: str\n",
    "        The name of the array\n",
    "\n",
    "    Returns:\n",
    "    str\n",
    "        A string indicating the missing values found in the dataset\n",
    "    '''\n",
    "   \n",
    "    return np.isnan(input_array).sum()\n",
    "\n",
    "def find_non_unique_features(x_set: np.ndarray, array_name: str) -> list:\n",
    "    ''' \n",
    "    Finds the features with non-unique values (i.e. only one value throughout)\n",
    "\n",
    "    Parameters:\n",
    "    x_set: np.ndarray\n",
    "        The dataset that contains features\n",
    "    array_name: str\n",
    "        The name of the array\n",
    "\n",
    "    Returns:\n",
    "    list\n",
    "        A list containing the features with non unique values\n",
    "    '''\n",
    "    # In the test set, there was one feature with 2 unique values, but I chose to keep this as if this feature has strong correlation with the target variablee, it could still be useful\n",
    "    num_features = x_set.shape[1]\n",
    "    unique_value_counts = [len(np.unique(x_set[:, i])) for i in range(num_features)]\n",
    "    filtered_features = [(i+1, count) for i, count in enumerate(unique_value_counts) if count == 1]\n",
    "\n",
    "    if len(filtered_features) == 0:\n",
    "        print(f\"No features with 1 unique value in {array_name}\")\n",
    "    else:\n",
    "        for feature, count in filtered_features:\n",
    "            print(\"Features with less than 100 unique values:\")\n",
    "            print(f\"Feature {feature}: {count} unique values\")\n",
    "    \n",
    "    return filtered_features\n",
    "\n",
    "# Assuming numerical features are not categorical\n",
    "def find_categorical_features(x_set: np.ndarray, array_name: str) -> list:\n",
    "    ''' \n",
    "    Finds the categorical features in a dataset\n",
    "\n",
    "    Parameters:\n",
    "    x_set: np.ndarray\n",
    "        The dataset that contains features\n",
    "    array_name: str\n",
    "        The name of the array\n",
    "\n",
    "    Returns:\n",
    "    list\n",
    "        A list containing the features that have categorical values\n",
    "        \n",
    "    '''\n",
    "    num_columns = x_set.shape[1]\n",
    "    categorical_features = []\n",
    "\n",
    "    for i in range(num_columns):\n",
    "        if not (is_int(x_set[0][i])) and not (is_float(x_set[0][i])):\n",
    "            categorical_features.append(i)\n",
    "\n",
    "    if len(categorical_features) == 0:\n",
    "        print(f\"No categorical features in {array_name}\")\n",
    "    else:\n",
    "        print(f\"There are {len(categorical_features)} categorical features\")\n",
    "\n",
    "    # If more than one column exists, encode it?\n",
    "    return categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This file contains all the functions required in transforming the datasets after pre-processing\n",
    "'''\n",
    "def normalise_min_max(train_set: np.ndarray, test_set: np.ndarray) -> tuple:\n",
    "    ''' \n",
    "    Normalises the datasets to the range (-1, 1) with MinMaxScaler\n",
    "\n",
    "    Parameters:\n",
    "    train_set: np.ndarray\n",
    "        The training dataset\n",
    "    test_set: np.ndarray\n",
    "        The testing dataset\n",
    "\n",
    "    Returns:\n",
    "    tuple\n",
    "        All the normalised datasets\n",
    "    '''\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    x_train_norm = min_max_scaler.fit_transform(train_set)\n",
    "    x_test_norm = min_max_scaler.fit_transform(test_set)\n",
    "    return x_train_norm, x_test_norm\n",
    "\n",
    "def normalise_min_max_task_3(train_set: np.ndarray, test_set: np.ndarray) -> tuple:\n",
    "    ''' \n",
    "    Normalises the datasets to the range (10, 15) with MinMaxScaler\n",
    "\n",
    "    Parameters:\n",
    "    train_set: np.ndarray\n",
    "        The training dataset\n",
    "    test_set: np.ndarray\n",
    "        The testing dataset\n",
    "\n",
    "    Returns:\n",
    "    tuple\n",
    "        All the normalised datasets\n",
    "    '''\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(10,15))\n",
    "    x_train_norm = min_max_scaler.fit_transform(train_set)\n",
    "    x_test_norm = min_max_scaler.transform(test_set)\n",
    "    return x_train_norm, x_test_norm\n",
    "\n",
    "def standardize_std_scaler(train_set: np.ndarray, test_set: np.ndarray) -> tuple:\n",
    "    ''' \n",
    "    Standardizes the datasets using StandardScaler\n",
    "\n",
    "    Parameters:\n",
    "    train_set: np.ndarray\n",
    "        The training dataset\n",
    "    test_set: np.ndarray\n",
    "        The testing dataset\n",
    "\n",
    "    Returns:\n",
    "    tuple\n",
    "        All the standardized datasets\n",
    "    '''\n",
    "    standard_scaler = StandardScaler()\n",
    "    x_train_norm = standard_scaler.fit_transform(train_set)\n",
    "    x_test_norm = standard_scaler.transform(test_set)\n",
    "    return x_train_norm, x_test_norm\n",
    "\n",
    "def normalise_robust_scaler(train_set: np.ndarray, test_set: np.ndarray) -> tuple:\n",
    "    ''' \n",
    "    Scales features with the median and interquartile range using RobustScaler\n",
    "\n",
    "    Parameters:\n",
    "    train_set: np.ndarray\n",
    "        The training dataset\n",
    "    test_set: np.ndarray\n",
    "        The testing dataset\n",
    "\n",
    "    Returns:\n",
    "    tuple\n",
    "        All the scaled datasets\n",
    "    '''\n",
    "    robust_scaler = RobustScaler()\n",
    "    x_train_norm = robust_scaler.fit_transform(train_set)\n",
    "    x_test_norm = robust_scaler.transform(test_set)\n",
    "    return x_train_norm, x_test_norm\n",
    "\n",
    "def find_lowest_occurring_class(dataset_y: np.ndarray) -> float:\n",
    "    ''' \n",
    "    Finds the class with the lowest occurrences of values\n",
    "\n",
    "    Parameters:\n",
    "    dataset_y: np.ndarray\n",
    "        The classes dataset\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The class with the lowest occurences\n",
    "    '''\n",
    "    unique_classes, class_counts = np.unique(dataset_y, return_counts=True)\n",
    "    min_count = np.argmin(class_counts)\n",
    "    lowest_occurrence_class = unique_classes[min_count]\n",
    "    return lowest_occurrence_class\n",
    "\n",
    "def find_highest_occurring_class(dataset_y: np.ndarray) -> float:\n",
    "    ''' \n",
    "    Finds the class with the highest occurrences of values\n",
    "\n",
    "    Parameters:\n",
    "    dataset_y: np.ndarray\n",
    "        The classes dataset\n",
    "\n",
    "    Returns:\n",
    "    float\n",
    "        The class with the highest occurences\n",
    "    '''\n",
    "    unique_classes, class_counts = np.unique(dataset_y, return_counts=True)\n",
    "    max_count = np.argmax(class_counts)\n",
    "    highest_occurrence_class = unique_classes[max_count]\n",
    "    return highest_occurrence_class\n",
    "\n",
    "def dataset_undersampling(dataset_x: np.ndarray, dataset_y: np.ndarray) -> tuple:\n",
    "    ''' \n",
    "    Used in imbalanced datasets to reduce the instances in the majority class to balance the class distribution\n",
    "\n",
    "    Parameters:\n",
    "    dataset_x: np.ndarray\n",
    "        The features dataset\n",
    "    dataset_y: np.ndarray\n",
    "        The classes dataset\n",
    "\n",
    "    Returns:\n",
    "    tuple\n",
    "        The undersampled versions of the input datasets\n",
    "    '''\n",
    "    lowest_occur_class = np.where(dataset_y == find_lowest_occurring_class(dataset_y))[0]\n",
    "    num_occurences = len(lowest_occur_class)\n",
    "\n",
    "    selected_indices_other_classes = []\n",
    "    for class_label in np.unique(dataset_y):\n",
    "        if class_label != find_lowest_occurring_class(dataset_y):\n",
    "            class_indices = np.where(dataset_y == class_label)[0]\n",
    "            selected_indices = np.random.choice(class_indices, size=num_occurences, replace=False)\n",
    "            selected_indices_other_classes.append(selected_indices)\n",
    "\n",
    "    balanced_indices = np.concatenate((lowest_occur_class, *selected_indices_other_classes))\n",
    "    x_balanced = dataset_x[balanced_indices]\n",
    "    y_balanced = dataset_y[balanced_indices]\n",
    "\n",
    "    return x_balanced, y_balanced\n",
    "\n",
    "def dataset_oversampling(dataset_x: np.ndarray, dataset_y: np.ndarray) -> tuple:\n",
    "    ''' \n",
    "    Used in imbalanced datasets to increase the instances in the minority class to balance the class distribution\n",
    "\n",
    "    Parameters:\n",
    "    dataset_x: np.ndarray\n",
    "        The features dataset\n",
    "    dataset_y: np.ndarray\n",
    "        The classes dataset\n",
    "\n",
    "    Returns:\n",
    "    tuple\n",
    "        The oversampled versions of the input datasets\n",
    "    '''\n",
    "    highest_occur_class = np.where(dataset_y == find_highest_occurring_class(dataset_y))[0]\n",
    "    num_occurences = len(highest_occur_class)\n",
    "\n",
    "    selected_indices_other_classes = []\n",
    "    for class_label in np.unique(dataset_y):\n",
    "        if class_label != find_highest_occurring_class(dataset_y):\n",
    "            class_indices = np.where(dataset_y == class_label)[0]\n",
    "            selected_indices = np.random.choice(class_indices, size=num_occurences)\n",
    "            selected_indices_other_classes.append(selected_indices)\n",
    "\n",
    "    balanced_indices = np.concatenate((highest_occur_class, *selected_indices_other_classes))\n",
    "    x_balanced = dataset_x[balanced_indices]\n",
    "    y_balanced = dataset_y[balanced_indices]\n",
    "\n",
    "    return x_balanced, y_balanced\n",
    "\n",
    "# ------ Task 4 ------\n",
    "\n",
    "# By reducing to 2, you're getting the 2 most important features\n",
    "def reduce_pca_dimensionality(train_set_x: np.ndarray, test_set_x: np.ndarray, components: int) -> tuple:\n",
    "    # ''' \n",
    "    # Finds the features with non-unique values (i.e. only one value throughout)\n",
    "\n",
    "    # Keyword Arguments:\n",
    "    # x_set: np.ndarray\n",
    "    #     The dataset that contains features\n",
    "    # array_name: str\n",
    "    #     The name of the array\n",
    "\n",
    "    # Returns:\n",
    "    # list\n",
    "    #     A list containing the features with non unique values\n",
    "    # '''\n",
    "    pca = PCA(n_components=components)\n",
    "    x_train_pca = pca.fit_transform(train_set_x)\n",
    "    x_test_pca = pca.transform(test_set_x)\n",
    "\n",
    "    return x_train_pca, x_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This file contains all the functions required in the feature selection phase\n",
    "'''\n",
    "def calculate_variance_threshold(train_set_x: np.ndarray, test_set_x: np.ndarray, top_10_features: bool) -> tuple:\n",
    "    '''\n",
    "    Finds and removes the low variance features from datasets\n",
    "\n",
    "    Parameters:\n",
    "    train_set_x: np.ndarray\n",
    "        The features training dataset\n",
    "    test_set_x: np.ndarray\n",
    "        The features testing dataset\n",
    "    top_10_features: bool\n",
    "        A boolean indicating whether only the top 10 features should be fetched or not\n",
    "\n",
    "    Returns:\n",
    "    top_10_features_train: np.ndarray\n",
    "        The top 10 features in the training dataset after variance threshold\n",
    "    top_10_features_test: np.ndarray\n",
    "        The top 10 features in the testing dataset after variance threshold\n",
    "    x_train_selected: np.ndarray\n",
    "        All features in the training dataset after variance threshold\n",
    "    x_test_selected: np.ndarray\n",
    "        All features in the testing dataset after variance threshold\n",
    "    '''\n",
    "    variances = np.var(train_set_x, axis=0)\n",
    "    average_variance = np.mean(variances) # To get the threshold value, the average of the variance for each feature was taken - 0.05\n",
    "\n",
    "    threshold = average_variance\n",
    "    variance_calculator = VarianceThreshold(threshold)\n",
    "    variance_calculator.fit(train_set_x)\n",
    "\n",
    "    if top_10_features:\n",
    "        kept_features_idx = variance_calculator.get_support(indices=True)\n",
    "        kept_features_variance = np.var(train_set_x[:, kept_features_idx], axis=0)\n",
    "        sorted_indices = np.argsort(kept_features_variance)[::-1]\n",
    "        top_10_features_train = kept_features_idx[sorted_indices][:10]\n",
    "        top_10_variance_train = kept_features_variance[sorted_indices][:10]\n",
    "\n",
    "        kept_features_variance_test = np.var(test_set_x[:, kept_features_idx], axis=0)\n",
    "        sorted_indices_test = np.argsort(kept_features_variance_test)[::-1]\n",
    "        top_10_features_test = kept_features_idx[sorted_indices_test][:10]\n",
    "        top_10_variance_test = kept_features_variance_test[sorted_indices_test][:10]\n",
    "\n",
    "        return top_10_features_train, top_10_features_test\n",
    "    else: \n",
    "        x_train_selected = variance_calculator.transform(train_set_x)\n",
    "        x_test_selected = variance_calculator.transform(test_set_x)\n",
    "        return x_train_selected, x_test_selected\n",
    "\n",
    "\n",
    "def pearson_correlation(train_set_x: np.ndarray, train_set_y: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the pearson correlation for all the features\n",
    "\n",
    "    Parameters:\n",
    "    train_set_x: np.ndarray\n",
    "        The features training dataset\n",
    "    train_set_y: np.ndarray\n",
    "        The classes training dataset\n",
    "\n",
    "    Returns:\n",
    "    imp_features: np.ndarray\n",
    "        A sorted array of the features with the highest correlation\n",
    "    '''\n",
    "    pr_coeff = r_regression(train_set_x, train_set_y)\n",
    "    imp_features = np.argsort(np.abs(pr_coeff))\n",
    "    return imp_features\n",
    "\n",
    "def f_regression_scores(train_set_x: np.ndarray, train_set_y: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates the f regression for all the features\n",
    "\n",
    "    Parameters:\n",
    "    train_set_x: np.ndarray\n",
    "        The features training dataset\n",
    "    train_set_y: np.ndarray\n",
    "        The classes training dataset\n",
    "\n",
    "    Returns:\n",
    "    imp_features: np.ndarray\n",
    "        A sorted array of the features\n",
    "    '''\n",
    "    f_scores, p_value = f_regression(train_set_x, train_set_y)\n",
    "    imp_features = np.argsort(np.abs(f_scores))\n",
    "    return imp_features\n",
    "\n",
    "def poisson_method(train_set_x: np.ndarray, train_set_y: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Performs feature selection using Poisson method\n",
    "\n",
    "    Parameters:\n",
    "    train_set_x: np.ndarray\n",
    "        The features training dataset\n",
    "    train_set_y: np.ndarray\n",
    "        The classes training dataset\n",
    "\n",
    "    Returns:\n",
    "    top_10_features_idx: np.ndarray\n",
    "        A sorted array of the features\n",
    "    '''\n",
    "    poisson_model = PoissonRegressor()\n",
    "    poisson_model.fit(train_set_x, train_set_y)\n",
    "    feature_importance = np.abs(poisson_model.coef_)\n",
    "    top_10_features_idx = np.argsort(feature_importance)[-10:]\n",
    "    top_10_features_train = train_set_x[:, top_10_features_idx]\n",
    "\n",
    "    return top_10_features_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This file contains all the functions required in training each model\n",
    "'''\n",
    "def svc_classifier(train_set_x: np.ndarray, test_set_x: np.ndarray, train_set_y: np.ndarray, test_set_y: np.ndarray) -> SVC:\n",
    "    ''' \n",
    "    Trains the model under a Support Vector Classifier\n",
    "\n",
    "    Parameters:\n",
    "    train_set_x: np.ndarray\n",
    "        The features training dataset\n",
    "    train_set_y: np.ndarray\n",
    "        The classes training dataset\n",
    "    test_set_x: np.ndarray\n",
    "        The features testing dataset\n",
    "    test_set_y: np.ndarray\n",
    "        The classes testing dataset\n",
    "\n",
    "    Returns:\n",
    "    svc: SVC\n",
    "        The trained model\n",
    "    '''\n",
    "    # kernel='rbf', C=1, gamma=\"scale\", probability=True\n",
    "    svc = SVC(probability=True) # Configuration derived from hyperparameter tuning\n",
    "    selected_features = train_set_x\n",
    "    selected_test_features = test_set_x\n",
    "    # concatenated_array_x = np.concatenate((selected_features, selected_test_features), axis=0)\n",
    "    # concatenated_array_y = np.concatenate((train_set_y, test_set_y), axis=0)\n",
    "    holdout_validation(svc, selected_features, selected_test_features, train_set_y, test_set_y)\n",
    "    cross_validation(svc, train_set_x, train_set_y)\n",
    "    # k_fold_valdiation(\"svc\", train_set_x, train_set_y, 20)\n",
    "    k_fold_cross_validation_strat(\"svc\", train_set_x, train_set_y, 10)\n",
    "\n",
    "    return svc\n",
    "\n",
    "def mlp_classifier(train_set_x: np.ndarray, test_set_x: np.ndarray, train_set_y: np.ndarray, test_set_y: np.ndarray) -> MLPClassifier:\n",
    "    ''' \n",
    "    Trains the model under a Multi Layer Perceptron Classifier\n",
    "\n",
    "    Parameters:\n",
    "    train_set_x: np.ndarray\n",
    "        The features training dataset\n",
    "    train_set_y: np.ndarray\n",
    "        The classes training dataset\n",
    "    test_set_x: np.ndarray\n",
    "        The features testing dataset\n",
    "    test_set_y: np.ndarray\n",
    "        The classes testing dataset\n",
    "\n",
    "    Returns:\n",
    "    mlp: MLPClassifier\n",
    "        The trained model\n",
    "    '''\n",
    "    # hidden_layer_sizes=(50, 100, 50), activation='tanh', solver='sgd', alpha=0.0001, random_state=42, shuffle=False\n",
    "    mlp = MLPClassifier(random_state=42, shuffle=False) # Configuration derived from hyperparameter tuning\n",
    "    mlp.fit(train_set_x, train_set_y)\n",
    "    # concatenated_array_x = np.concatenate((train_set_x, test_set_x), axis=0)\n",
    "    # concatenated_array_y = np.concatenate((train_set_y, test_set_y), axis=0)\n",
    "    holdout_validation(mlp, train_set_x, test_set_x, train_set_y, test_set_y)\n",
    "    cross_validation(mlp, train_set_x, train_set_y)\n",
    "    # k_fold_valdiation(\"mlp\", train_set_x, train_set_y, 20)\n",
    "    k_fold_cross_validation_strat(\"mlp\", train_set_x, train_set_y, 10)\n",
    "\n",
    "    return mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This file contains all the functions used for validating the models\n",
    "'''\n",
    "def holdout_validation(classifier: Union[MLPClassifier, SVC], train_set_x: np.ndarray, test_set_x: np.ndarray, train_set_y: np.ndarray, test_set_y: np.ndarray) -> Union[MLPClassifier|SVC]:\n",
    "    '''\n",
    "    Performs holdout validation on the classifier used for training\n",
    "\n",
    "    Parameters:\n",
    "    classifier: Union[SVC, MLPClassifier]\n",
    "        The model that was trained during development - Only accepts SVC and MLP for now\n",
    "    train_set_x: np.ndarray\n",
    "        The features training dataset\n",
    "    test_set_x: np.ndarray\n",
    "        The features testing dataset\n",
    "    train_set_y: np.ndarray\n",
    "        The classes training dataset\n",
    "    test_set_y: np.ndarray\n",
    "        The classes testing dataset\n",
    "    \n",
    "    Returns:\n",
    "    classifier: Union[SVC, MLPClassifier]\n",
    "        The classifer that was validated\n",
    "    '''\n",
    "    classifier.fit(train_set_x, train_set_y)\n",
    "    print(\"------ Holdout Validation ------\")\n",
    "    print(f\"Training Accuracy: {classifier.score(train_set_x, train_set_y)}\")\n",
    "    print(f\"Testing Accuracy: {classifier.score(test_set_x, test_set_y)}\")\n",
    "    return classifier\n",
    "\n",
    "def cross_validation(classifier: Union[MLPClassifier, SVC], train_set_x: np.ndarray, train_set_y: np.ndarray) -> Union[MLPClassifier, SVC]:\n",
    "    '''\n",
    "    Performs cross validation on the classifier used for training\n",
    "\n",
    "    Parameters:\n",
    "    classifier: Union[SVC, MLPClassifier]\n",
    "        The model that was trained during development - Only accepts SVC and MLP for now\n",
    "    train_set_x: np.ndarray\n",
    "        The features training dataset\n",
    "    train_set_y: np.ndarray\n",
    "        The classes training dataset\n",
    "    \n",
    "    Returns:\n",
    "    classifier: Union[SVC, MLPClassifier]\n",
    "        The classifer that was validated\n",
    "    '''\n",
    "    cv_score = cross_val_score(classifier, train_set_x, train_set_y)\n",
    "    print(\"------ Cross Validation ------\")\n",
    "    print(f\"Mean Accuracy: {cv_score.mean()}\")\n",
    "    return classifier\n",
    "\n",
    "# def k_fold_valdiation(classifier: Union[MLPClassifier, SVC], train_set_x: np.ndarray, train_set_y: np.ndarray, size: int) -> Union[MLPClassifier, SVC]:\n",
    "#     '''\n",
    "#     Performs K-fold validation on the classifier used for training\n",
    "\n",
    "#     Parameters:\n",
    "#     classifier: Union[SVC, MLPClassifier]\n",
    "#         The model that was trained during development - Only accepts SVC and MLP for now\n",
    "#     train_set_x: np.ndarray\n",
    "#         The features training dataset\n",
    "#     train_set_y: np.ndarray\n",
    "#         The classes training dataset\n",
    "#     size: int\n",
    "#         The number of folds\n",
    "    \n",
    "#     Returns:\n",
    "#     classifier: Union[SVC, MLPClassifier]\n",
    "#         The classifer that was validated\n",
    "#     '''\n",
    "#     kf = KFold(n_splits=size, shuffle=True)\n",
    "#     tracked_scores = np.zeros(size)\n",
    "#     index = 0\n",
    "#     for train_idx, test_idx in kf.split(train_set_x):\n",
    "#         x_train_kfold, x_test_kfold = train_set_x[train_idx], train_set_x[test_idx]\n",
    "#         y_train_kfold, y_test_kfold = train_set_y[train_idx], train_set_y[test_idx]\n",
    "\n",
    "#         if classifier == \"svc\":\n",
    "#             # kernel='rbf', C=1, gamma=\"scale\"\n",
    "#             svc_clf = SVC()\n",
    "#             svc_clf.fit(x_train_kfold, y_train_kfold)\n",
    "#             tracked_scores[index] = svc_clf.score(x_test_kfold, y_test_kfold)\n",
    "#             index += 1\n",
    "#         else:\n",
    "#             # hidden_layer_sizes=(100,), activation='tanh', solver='adam', alpha=0.05, random_state=42)\n",
    "#             mlp = MLPClassifier()\n",
    "#             mlp.fit(x_train_kfold, y_train_kfold)\n",
    "#             tracked_scores[index] = mlp.score(x_test_kfold, y_test_kfold)\n",
    "#             index += 1\n",
    "\n",
    "#     print(\"------ K fold Validation ------\")\n",
    "#     print(f\"Mean Accuracy: {tracked_scores.mean()}\")\n",
    "#     print(f\"Std Deviation: {tracked_scores.std()}\")\n",
    "#     return classifier\n",
    "\n",
    "def k_fold_cross_validation_strat(classifier: Union[MLPClassifier, SVC], train_set_x: np.ndarray, train_set_y: np.ndarray, size: int) -> Union[MLPClassifier, SVC]:\n",
    "    '''\n",
    "    Performs stratified K-fold validation on the classifier used for training\n",
    "\n",
    "    Parameters:\n",
    "    classifier: Union[SVC, MLPClassifier]\n",
    "        The model that was trained during development - Only accepts SVC and MLP for now\n",
    "    train_set_x: np.ndarray\n",
    "        The features training dataset\n",
    "    train_set_y: np.ndarray\n",
    "        The classes training dataset\n",
    "    size: int\n",
    "        The number of folds\n",
    "    \n",
    "    Returns:\n",
    "    classifier: Union[SVC, MLPClassifier]\n",
    "        The classifer that was validated\n",
    "    '''    \n",
    "    kf_strat = StratifiedKFold(n_splits=size, shuffle=True)\n",
    "    tracked_scores = np.zeros(size)\n",
    "    index = 0\n",
    "    for train_idx, test_idx in kf_strat.split(train_set_x, train_set_y):\n",
    "        x_train_kfold, x_test_kfold = train_set_x[train_idx], train_set_x[test_idx]\n",
    "        y_train_kfold, y_test_kfold = train_set_y[train_idx], train_set_y[test_idx]\n",
    "\n",
    "        if classifier == \"svc\":\n",
    "            # kernel='rbf', C=1, gamma=\"scale\"\n",
    "            svc_clf = SVC()\n",
    "            svc_clf.fit(x_train_kfold, y_train_kfold)\n",
    "            tracked_scores[index] = svc_clf.score(x_test_kfold, y_test_kfold)\n",
    "            index += 1\n",
    "        else:\n",
    "            # hidden_layer_sizes=(100,), activation='tanh', solver='adam', alpha=0.05, random_state=42\n",
    "            mlp = MLPClassifier()\n",
    "            mlp.fit(x_train_kfold, y_train_kfold)\n",
    "            tracked_scores[index] = mlp.score(x_test_kfold, y_test_kfold)\n",
    "            index += 1\n",
    "\n",
    "    print(\"------ Stratified K fold Validation ------\")\n",
    "    print(f\"Mean Accuracy: {tracked_scores.mean()}\")\n",
    "    print(f\"Std Deviation: {tracked_scores.std()}\")\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This file contains all the functions used for evaluating the models\n",
    "'''\n",
    "def fetch_classification_report(classifier: Union[SVC, MLPClassifier], test_set_x: np.ndarray, test_set_y: np.ndarray) -> None:\n",
    "    '''\n",
    "    Creates the classification report for a classifier to evaluate the precision, recall, f1-score, and support\n",
    "\n",
    "    Parameters:\n",
    "    classifier: Union[SVC, MLPClassifier]\n",
    "        The classifier that was trained during development - Only accepts SVC and MLP for now\n",
    "    test_set_x: np.ndarray\n",
    "        The features testing dataset\n",
    "    test_set_y: np.ndarray\n",
    "        The classes testing dataset\n",
    "    '''\n",
    "    y_pred = classifier.predict(test_set_x)\n",
    "    print(\"----- Classification Report -----\")\n",
    "    print(classification_report(test_set_y, y_pred))\n",
    "\n",
    "def fetch_multiple_classification_report(classifiers: Union[SVC, MLPClassifier], classifier_titles: list[str], test_set_x: np.ndarray, test_set_y: np.ndarray):\n",
    "    '''\n",
    "    Creates multiple classification reports used for comparison\n",
    "\n",
    "    Parameters:\n",
    "    classifiers: Union[SVC, MLPClassifier]\n",
    "        The classifier that was trained during development - Only accepts SVC and MLP for now\n",
    "    classifier_titles: list[str]\n",
    "        The list of all titles for each report\n",
    "    test_set_x: np.ndarray\n",
    "        The features testing dataset\n",
    "    test_set_y: np.ndarray\n",
    "        The classes testing dataset\n",
    "    '''\n",
    "    for idx in range(len(classifiers)):\n",
    "        y_pred = classifiers[idx].predict(test_set_x)\n",
    "        print(f\"----- {classifier_titles[idx]} -----\\n{classification_report(test_set_y, y_pred)}\")\n",
    "\n",
    "def fetch_accuracy_score(test_set_y: np.ndarray, predicted_set_y: np.ndarray):\n",
    "    '''\n",
    "    Details the accuracy of a model based on the actual and predicted values\n",
    "\n",
    "    Parameters:\n",
    "    test_set_y: np.ndarray\n",
    "        The classes testing dataset\n",
    "    predicted_set_y: np.ndarray\n",
    "        The predictions made by the model\n",
    "    '''\n",
    "    accuracy = accuracy_score(test_set_y, predicted_set_y)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "def fetch_log_loss(test_set_y: np.ndarray, predicted_set_y: np.ndarray):\n",
    "    '''\n",
    "    Details the log loss of a model based on the actual and predicted values\n",
    "\n",
    "    Parameters:\n",
    "    test_set_y: np.ndarray\n",
    "        The classes testing dataset\n",
    "    predicted_set_y: np.ndarray\n",
    "        The predictions made by the model\n",
    "    '''\n",
    "    lg_loss = log_loss(test_set_y, predicted_set_y)\n",
    "    print(f\"Log Loss: {lg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This file contains all the functions required to plot the visualisations\n",
    "'''\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, auc, roc_curve, det_curve\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "\n",
    "def plot_feature_split_of_values(input_arrays: list[np.ndarray], labels: list[str]):\n",
    "    ''' \n",
    "    Plots a histogram showing the split of values in each feature dataset \n",
    "\n",
    "    Parameters:\n",
    "    input_arrays: list[np.ndarray]\n",
    "        The datasets containing the the plottable inputs\n",
    "    labels: list[str]\n",
    "        The titles for the datasets\n",
    "    '''\n",
    "    fig, axs = plt.subplots(1, len(input_arrays), figsize=(15, 4)) \n",
    "    fig.suptitle('Split of Values', fontsize=16)\n",
    "    \n",
    "    for idx, input_array in enumerate(input_arrays):\n",
    "        flattened_array = input_array.flatten()\n",
    "        axs[idx].hist(flattened_array, bins=50, color='blue', alpha=0.7)\n",
    "        axs[idx].set_title(f'{labels[idx]}')\n",
    "        axs[idx].set_xlabel('Values')\n",
    "        axs[idx].set_ylabel('Frequency')\n",
    "        axs[idx].set_xlim(0, 3)\n",
    "        axs[idx].set_xticks(np.arange(0, 3.1, 0.25))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_class_split_of_values(input_arrays: list[np.ndarray], labels: list[str]):\n",
    "    ''' \n",
    "    Plots a histogram showing the split of values of each class\n",
    "\n",
    "    Parameters:\n",
    "    input_arrays: list[np.ndarray]\n",
    "        The datasets containing the the plottable inputs\n",
    "    labels: list[str]\n",
    "        The titles for the datasets\n",
    "    '''\n",
    "    fig, axs = plt.subplots(1, len(input_arrays), figsize=(15, 4)) \n",
    "    fig.suptitle('Split of Values', fontsize=16)\n",
    "    \n",
    "    for idx, input_array in enumerate(input_arrays):\n",
    "        flattened_array = input_array.flatten()\n",
    "        axs[idx].hist(flattened_array, bins=50, color='blue', alpha=0.7)\n",
    "        axs[idx].set_title(f'{labels[idx]}')\n",
    "        axs[idx].set_xlabel('Values')\n",
    "        axs[idx].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_single_correlation_heatmap(corr_matrix: np.corrcoef, title: str):\n",
    "    ''' \n",
    "    Plots a heatmap showing the corrlation between all features and target variables \n",
    "\n",
    "    Parameters:\n",
    "    corr_matrix: np.corrcoef\n",
    "        The correlation matrix between the features and the target variable\n",
    "    title: str\n",
    "        The title for the figure\n",
    "    '''\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(corr_matrix, cmap='coolwarm', interpolation='nearest')\n",
    "    plt.colorbar(label='Correlation')\n",
    "    plt.xticks(np.arange(corr_matrix.shape[0]), np.arange(1, corr_matrix.shape[0] + 1), rotation=45)\n",
    "    plt.yticks(np.arange(corr_matrix.shape[0]), np.arange(1, corr_matrix.shape[0] + 1))\n",
    "    plt.title('Pearson Correlation Heatmap')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title(title)\n",
    "    for idx in range(corr_matrix.shape[0]):\n",
    "            for idj in range(corr_matrix.shape[1]):\n",
    "                plt.text(idj, idx, '{:.2f}'.format(corr_matrix[idx, idj]), ha='center', va='center', color='black')\n",
    "    plt.show()\n",
    "\n",
    "def plot_correlation_heatmap(ax, corr_matrix, title):\n",
    "    im = ax.imshow(corr_matrix, cmap='coolwarm', interpolation='nearest')\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Correlation')\n",
    "    ax.set_xticks(np.arange(corr_matrix.shape[0]))\n",
    "    ax.set_yticks(np.arange(corr_matrix.shape[0]))\n",
    "    ax.set_xticklabels(np.arange(1, corr_matrix.shape[0] + 1), rotation=45)\n",
    "    ax.set_yticklabels(np.arange(1, corr_matrix.shape[0] + 1))\n",
    "    ax.set_title(title)\n",
    "    for idx in range(corr_matrix.shape[0]):\n",
    "        for idj in range(corr_matrix.shape[1]):\n",
    "            ax.text(idj, idx, '{:.2f}'.format(corr_matrix[idx, idj]), ha='center', va='center', color='black')\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(classifier: Union[SVC, MLPClassifier], test_set_x: np.ndarray, test_set_y: np.ndarray, table_needed: bool):\n",
    "    ''' \n",
    "    Plots a confusion matrix to show the key metrics (i.e. the True Positive, True Negative, False Positive, and False Negative) for each class\n",
    "\n",
    "    Parameters:\n",
    "    classifier: Union[SVC, MLPClassifier]\n",
    "        The classifier that was trained during development - Only accepts SVC and MLP for now\n",
    "    test_set_x: np.ndarray\n",
    "        The features testing dataset\n",
    "    test_set_y: np.ndarray\n",
    "        The classes testing dataset\n",
    "    table_needed: bool\n",
    "        This determines whether a table should be created as well for each of the metrics mentioned above\n",
    "    '''\n",
    "    confusion_matrix_values = []\n",
    "    y_pred = classifier.predict(test_set_x)\n",
    "    ConfusionMatrixDisplay.from_predictions(test_set_y, y_pred)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    conf_mtrx = confusion_matrix(test_set_y, y_pred)\n",
    "    \n",
    "    if table_needed:\n",
    "        for idx in range(len(conf_mtrx)):\n",
    "            TP = conf_mtrx[idx, idx]\n",
    "            FP = np.sum(conf_mtrx[:, idx]) - TP\n",
    "            FN = np.sum(conf_mtrx[idx, :]) - TP\n",
    "            TN = np.sum(conf_mtrx) - (TP + FP + FN)\n",
    "            confusion_matrix_values.append((TP, FP, FN, TN))\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        table = ax.table(cellText=confusion_matrix_values,\n",
    "                        colLabels=['True Positive', 'False Positive', 'False Negative', 'True Negative'],\n",
    "                        rowLabels=[\n",
    "                            'Class 0', 'Class 1', 'Class 2', 'Class 3',\n",
    "                            'Class 4', 'Class 5',\n",
    "                            'Class 6', 'Class 7', 'Class 8',\n",
    "                            'Class 9'\n",
    "                        ],\n",
    "                        loc='center')\n",
    "\n",
    "        table.scale(1.2, 1)\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "def plot_precision_recall_curve(test_set_y: np.ndarray, pred_set_y: np.ndarray, ax: plt.axes):\n",
    "    ''' \n",
    "    Plots a precision recall curve to see the rate of (i) true positive predictions to the total positive predictions \n",
    "    and (ii) true positive predictions to the true positives.\n",
    "\n",
    "    Parameters:\n",
    "    test_set_y: np.ndarray\n",
    "        The classes testing dataset\n",
    "    pred_set_y: np.ndarray\n",
    "        The predictions made on the testing data\n",
    "    ax: plt.axes\n",
    "        Axis when plotting subfigures\n",
    "    '''\n",
    "    for idx in range(len(np.unique(test_set_y))):\n",
    "        precision, recall, _ = precision_recall_curve((test_set_y == idx).astype(int), pred_set_y[:, idx])\n",
    "        ax.plot(recall, precision, lw=2, label='Class {}'.format(idx))\n",
    "\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title('Precision-Recall Curve')\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "def plot_roc_curve(test_set_y, pred_set_y, ax):\n",
    "    ''' \n",
    "    Plots an ROC curve to see the rate of true positives to false positives\n",
    "\n",
    "    Parameters:\n",
    "    test_set_y: np.ndarray\n",
    "        The classes testing dataset\n",
    "    pred_set_y: np.ndarray\n",
    "        The predictions made on the testing data\n",
    "    ax: plt.axes\n",
    "        Axis when plotting subfigures\n",
    "    '''\n",
    "    for idx in range(len(np.unique(test_set_y))):\n",
    "        fpr, tpr, _ = roc_curve((test_set_y == idx).astype(int), pred_set_y[:, idx])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        ax.plot(fpr, tpr, lw=2, label='Class {}'.format(idx, roc_auc))\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC Curve')\n",
    "    ax.legend(loc='lower right')\n",
    "\n",
    "def plot_det_curve(test_set_y, pred_set_y, ax):\n",
    "    ''' \n",
    "    Plots a DET curve to see the rate of false negatives to false positives\n",
    "\n",
    "    Parameters:\n",
    "    test_set_y: np.ndarray\n",
    "        The classes testing dataset\n",
    "    pred_set_y: np.ndarray\n",
    "        The predictions made on the testing data\n",
    "    ax: plt.axes\n",
    "        Axis when plotting subfigures\n",
    "    '''\n",
    "    for idx in range(len(np.unique(test_set_y))):\n",
    "        fpr, fnr, _ = det_curve((test_set_y == idx).astype(int), pred_set_y[:, idx])\n",
    "        ax.plot(fpr, fnr, lw=2, label='Class {}'.format(idx))\n",
    "\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('False Negative Rate')\n",
    "    ax.set_title('DET Curve')\n",
    "    ax.legend(loc='best')\n",
    "\n",
    "def plot_predicted_vs_actual(test_set_y: np.ndarray, pred_set_y: np.ndarray, title: str, ax: plt.axes, no_of_plots: int):\n",
    "    ''' \n",
    "    Plots a scatter plot showing the predicted vs actual values. \n",
    "    It is done only with 100 occurences so that the outputs are visible.\n",
    "\n",
    "    Parameters:\n",
    "    test_set_y: np.ndarray\n",
    "        The classes testing dataset\n",
    "    pred_set_y: np.ndarray\n",
    "        The predictions made on the testing data\n",
    "    title: str\n",
    "        Title of the plot\n",
    "    ax: plt.axes\n",
    "        Axis when plotting subfigures\n",
    "    no_of_plots: int\n",
    "        The number of plots that the predictions vs actuals are shown\n",
    "    '''\n",
    "    ax.plot(test_set_y[:no_of_plots], 'o', label='Actual')\n",
    "    ax.plot(pred_set_y[:no_of_plots], 'x', label='Prediction')\n",
    "    ax.set_xlabel('Actual/Predicted value of the target')\n",
    "    ax.set_ylabel('Index of sample')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "# ------ TASK 4 ------\n",
    "\n",
    "# def plot_clustering_results(train_set_x, test_set_x, clusters):\n",
    "\n",
    "#     kmeans = KMeans(n_clusters=clusters)\n",
    "#     kmeans.fit(train_set_x)\n",
    "#     cluster_labels = kmeans.predict(test_set_x)\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.scatter(train_set_x[:, 0], test_set_x[:, 1], c=cluster_labels, cmap='viridis', s=50, alpha=0.5)\n",
    "#     plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='x', s=200, c='red', label='Cluster Centers')\n",
    "#     plt.title('PCA Reduced Testing Dataset with K-means Clustering')\n",
    "#     plt.xlabel('Principal Component 1')\n",
    "#     plt.ylabel('Principal Component 2')\n",
    "#     plt.colorbar(label='Cluster')\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This file contains all the functions required for miscellaneous use-cases\n",
    "'''\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def is_float(string):\n",
    "    '''\n",
    "    Check if a string can be converted to float\n",
    "    '''\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_int(string):\n",
    "    '''\n",
    "    Check if a string can be converted to int\n",
    "    '''\n",
    "    try:\n",
    "        int(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def save_dataset(model, file_name):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"{file_name} has the new dataset!\")\n",
    "    \n",
    "def load_dataset(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This file contains all the functions required for model operations post training\n",
    "'''\n",
    "def save_model(model: Union[SVC, MLPClassifier], file_name: str):\n",
    "    '''\n",
    "    Saves the model using pickle\n",
    "\n",
    "    Parameters:\n",
    "    model: Union[SVC, MLPClassifier]\n",
    "        The model that was trained during development - Only accepts SVC and MLP for now\n",
    "    file_name: str\n",
    "        The classes training dataset\n",
    "    '''\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"{file_name} has the new model!\")\n",
    "\n",
    "def load_model(file_name: str):\n",
    "    '''\n",
    "    Loads the model using pickle\n",
    "\n",
    "    Parameters:\n",
    "    file_name: str\n",
    "        The path where the model was saved\n",
    "    \n",
    "    Returns:\n",
    "        The loaded model\n",
    "    '''\n",
    "    with open(file_name, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "def find_best_configuration_svc(parameters: dict, train_set_x: np.ndarray, test_set_x: np.ndarray, train_set_y: np.ndarray, test_set_y: np.ndarray) -> dict:\n",
    "    '''\n",
    "    Performs manual hyperparameter optimisation to find the best configuration for the SVC classifier\n",
    "\n",
    "    Parameters:\n",
    "    parameters: dict\n",
    "        All the parameters to be experimented with\n",
    "    train_set_x: str\n",
    "        The features training dataset\n",
    "    test_set_x: str\n",
    "        The features testing dataset\n",
    "    train_set_y: str\n",
    "        The classes training dataset\n",
    "    test_set_y: str\n",
    "        The classes testing dataset\n",
    "    \n",
    "    Returns:\n",
    "        The best parameter configuration with the accuracy\n",
    "    '''\n",
    "    selected_c = 0 \n",
    "    selected_kernel = ''\n",
    "    selected_gamma = '' \n",
    "    best_training = 0\n",
    "    best_test = 0\n",
    "\n",
    "    for values in range(len(parameters[\"kernels_values\"])):\n",
    "     for c_vals in range(len(parameters[\"c_values\"])):\n",
    "          for g_values in range(len(parameters[\"gamma_values\"])):\n",
    "                svc_clf = SVC(C=parameters[\"c_values\"][c_vals], gamma=parameters[\"gamma_values\"][g_values], kernel=parameters[\"kernels_values\"][values])\n",
    "                svc_clf.fit(train_set_x, train_set_y)\n",
    "                current_train = svc_clf.score(train_set_x, train_set_y) \n",
    "                current_test = svc_clf.score(test_set_x, test_set_y)\n",
    "                cv_score = cross_val_score(svc_clf, train_set_x, train_set_y, cv=10)\n",
    "\n",
    "                if (current_train > best_training) and (current_test > best_test):\n",
    "                    best_training = current_train\n",
    "                    best_test = current_test\n",
    "                    selected_c = parameters[\"c_values\"][c_vals]\n",
    "                    selected_kernel = parameters[\"kernels_values\"][values]\n",
    "                    selected_gamma = parameters[\"gamma_values\"][g_values]\n",
    "\n",
    "    return {\n",
    "        \"parameters\": {\"c\": selected_c, \"kernel\": selected_kernel, \"gamma\": selected_gamma},\n",
    "        \"training_accuracy\": best_training,\n",
    "        \"testing_accuracy\": best_test\n",
    "    }\n",
    "\n",
    "def find_best_configuration_mlp(parameters: dict, train_set_x: np.ndarray, test_set_x: np.ndarray, train_set_y: np.ndarray, test_set_y: np.ndarray) -> dict:\n",
    "    '''\n",
    "    Performs manual hyperparameter optimisation to find the best configuration for the MLP classifier\n",
    "\n",
    "    Parameters:\n",
    "    parameters: dict\n",
    "        All the parameters to be experimented with\n",
    "    train_set_x: str\n",
    "        The features training dataset\n",
    "    test_set_x: str\n",
    "        The features testing dataset\n",
    "    train_set_y: str\n",
    "        The classes training dataset\n",
    "    test_set_y: str\n",
    "        The classes testing dataset\n",
    "    \n",
    "    Returns:\n",
    "        The best parameter configuration with the accuracy\n",
    "    '''\n",
    "    selected_hidden_layers = 0 \n",
    "    selected_activation = ''\n",
    "    selected_solver = '' \n",
    "    selected_alpha = '' \n",
    "    best_training = 0\n",
    "    best_test = 0\n",
    "    outer_cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    for layer in range(len(parameters[\"hidden_layers\"])):\n",
    "        for activation in range(len(parameters[\"activations\"])):\n",
    "            for solver in range(len(parameters[\"solvers\"])):\n",
    "                for alpha in range(len(parameters[\"alphas\"])):\n",
    "                        inner_scores = []\n",
    "                        mlp_clf = MLPClassifier(hidden_layer_sizes=parameters[\"hidden_layers\"][layer], activation=parameters[\"activations\"][activation], solver=parameters[\"solvers\"][solver], alpha=parameters[\"alphas\"][alpha])\n",
    "                        mlp_clf.fit(train_set_x, train_set_y)\n",
    "                        current_train = mlp_clf.score(train_set_x, train_set_y)\n",
    "                        current_test = mlp_clf.score(test_set_x, test_set_y)\n",
    "                        # Nested CV\n",
    "                        for train_index, val_index in outer_cv.split(train_set_x):\n",
    "                            X_train, X_val = train_set_x[train_index], train_set_x[val_index]\n",
    "                            Y_train, Y_val = train_set_y[train_index], train_set_y[val_index]\n",
    "                            mlp_clf.fit(X_train, Y_train)\n",
    "                            test_score = mlp_clf.fit(X_val, Y_val)\n",
    "                            inner_scores.append(test_score)\n",
    "                        \n",
    "                        mean_score = sum(inner_scores) / len(inner_scores)\n",
    "                        if (current_train > best_training) and (current_test > best_test):\n",
    "                            best_training = current_train\n",
    "                            best_test = current_test\n",
    "                            selected_hidden_layers = parameters[\"hidden_layers\"][layer]\n",
    "                            selected_activation = parameters[\"activations\"][activation]\n",
    "                            selected_solver = parameters[\"solvers\"][solver]\n",
    "                            selected_alpha = parameters[\"alphas\"][alpha]\n",
    "\n",
    "    return {\n",
    "        \"parameters\": {\"hidden_layers\": selected_hidden_layers, \"activation\": selected_activation, \"solver\": selected_solver, \"alpha\": selected_alpha},\n",
    "        \"training_accuracy\": best_training,\n",
    "        \"testing_accuracy\": best_test\n",
    "    }\n",
    "\n",
    "                        # print(f\"------- With hidden_layers={hidden_layers[layer]}, activation={activations[activation]}, solver={solvers[solver]}, alpha={alphas[alpha]}\")\n",
    "                        # holdout_validation(mlp_clf, x_train_norm, x_test_norm, y_train, y_test)\n",
    "                        # print(f\"Mean - {mean_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
